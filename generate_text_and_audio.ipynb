{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pIZ3ZXNp7cf"
   },
   "source": [
    "## Welcome to Stockastic Piraites! 🏴‍☠️🏴‍☠️🏴‍☠️ 🦜\n",
    "\n",
    "### Libraries versions\n",
    "Correct version of torch is important!\n",
    "- pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121\n",
    "- pip3 install transformers==4.31.0\n",
    "- pip install ctransformers\n",
    "- pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0.dev20231218+cu121\n",
      "CUDA is available in your PyTorch installation.\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "# Print the result\n",
    "if cuda_available:\n",
    "    print(\"CUDA is available in your PyTorch installation.\")\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA is not available in your PyTorch installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Replace 'your_pid_here' with the actual PID of the process you want to stop\n",
    "#process_pid = 1175331\n",
    "\n",
    "# Call the function to stop the process\n",
    "#stop_process(process_pid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restart Kernel\n",
    "restart = True\n",
    "if restart:\n",
    "    import IPython\n",
    "    #IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
    "    IPython.Application.instance().kernel.do_restart() #does not automatically restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/tortoise/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/root/miniconda/envs/tortoise/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model path '/workspace/data/mistral_model/mistral-7b-instruct-v0.1.Q4_K_M.gguf' doesn't exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m tts \u001b[38;5;241m=\u001b[39m TextToSpeech(use_deepspeed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, kv_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/data/mistral_model/mistral-7b-instruct-v0.1.Q4_K_M.gguf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistral-7b-instruct-v0.1.Q4_K_M.gguf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistral\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/tortoise/lib/python3.9/site-packages/ctransformers/hub.py:151\u001b[0m, in \u001b[0;36mAutoModelForCausalLM.from_pretrained\u001b[0;34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gptq\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gptq\u001b[38;5;241m.\u001b[39mAutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    145\u001b[0m         model_path_or_repo_id,\n\u001b[1;32m    146\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    147\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    149\u001b[0m     )\n\u001b[0;32m--> 151\u001b[0m config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m model_type \u001b[38;5;241m=\u001b[39m model_type \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type\n\u001b[1;32m    159\u001b[0m path_type \u001b[38;5;241m=\u001b[39m get_path_type(model_path_or_repo_id)\n",
      "File \u001b[0;32m~/miniconda/envs/tortoise/lib/python3.9/site-packages/ctransformers/hub.py:40\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, model_path_or_repo_id, local_files_only, revision, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m path_type \u001b[38;5;241m=\u001b[39m get_path_type(model_path_or_repo_id)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path_type:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m config \u001b[38;5;241m=\u001b[39m Config()\n\u001b[1;32m     43\u001b[0m auto_config \u001b[38;5;241m=\u001b[39m AutoConfig(config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "\u001b[0;31mValueError\u001b[0m: Model path '/workspace/data/mistral_model/mistral-7b-instruct-v0.1.Q4_K_M.gguf' doesn't exist."
     ]
    }
   ],
   "source": [
    "# Imports used through the rest of the notebook.\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import IPython\n",
    "\n",
    "from tortoise.api import TextToSpeech\n",
    "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "#preset super_fast, fast, standard, high_quality\n",
    "preset = \"fast\"\n",
    "\n",
    "# This will download all the models used by Tortoise from the HF hub.\n",
    "tts = TextToSpeech(use_deepspeed=False, kv_cache=True, device='cuda')\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"/workspace/data/mistral_model/mistral-7b-instruct-v0.1.Q4_K_M.gguf\", model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", model_type=\"mistral\", gpu_layers=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is Monday\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def get_day_of_week():\n",
    "    # Get the current date and time\n",
    "    current_datetime = datetime.datetime.now()\n",
    "\n",
    "    # Use the strftime method to format the date and extract the day of the week\n",
    "    day_of_week = current_datetime.strftime(\"%A\")\n",
    "\n",
    "    return day_of_week\n",
    "\n",
    "# Call the function and print the result\n",
    "day = get_day_of_week()\n",
    "print(\"Today is\", day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of topics 6\n"
     ]
    }
   ],
   "source": [
    "#Create a list of topics\n",
    "generalTopics = [\"God\", \"chat G.P.T. religion\", \"quantum physics\", \"A.I. will make human useless\", \"descoveries in the human brain\", \"close the program\"]\n",
    "\n",
    "listOFTopics = [\"They talk about if god exist or not, for instance if God created the universe and god is omniscient, omnipotent and omnibenevolent, why is needed a simulation? make it funny\",\n",
    "                \"They talk about chat G.P.T. inventing a new religion that all humans are going to follow blindly\",\n",
    "                \"They explain quantum physics for advanced audience, use complex terms\",\n",
    "                \"They talk about A.I. will make humans useless, for instance, if A.I. can do everything, why do we need humans?\",\n",
    "                \"They talk about recent descoveries in the human brain, make it funny\",\n",
    "                \"They close the program, the Radio program is called 'Stockastic Piraites', make it funny\"]\n",
    "\n",
    "print(\"number of topics\", len(listOFTopics))\n",
    "preTopic = \"Generate a radio conversation of two commentators, Anna and Phillip. \"\n",
    "topic = \"\"\n",
    "postTopic = \". Don't bring more people into the conversation, only two voices. Only refers to them with their names, avoid adding time or other elements.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "--------------------------------------\n",
      "Generate a radio conversation of two commentators, Anna and Phillip. Start with greetings too all the audience, knowing that today is Monday. They talk about if god exist or not, for instance if God created the universe and god is omniscient, omnipotent and omnibenevolent, why is needed a simulation? make it funny. Don't bring more people into the conversation, only two voices. Only refers to them with their names, avoid adding time or other elements.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n",
      "Number of tokens (516) exceeded maximum context length (512).\n",
      "Number of tokens (517) exceeded maximum context length (512).\n",
      "Number of tokens (518) exceeded maximum context length (512).\n",
      "Number of tokens (519) exceeded maximum context length (512).\n",
      "Number of tokens (520) exceeded maximum context length (512).\n",
      "Number of tokens (521) exceeded maximum context length (512).\n",
      "Number of tokens (522) exceeded maximum context length (512).\n",
      " 17%|█▋        | 1/6 [00:17<01:29, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Anna: Good morning everyone! It's Monday, let's get ready for a new week. Today we are going to talk about something that has been debated for centuries, do you believe in God?\n",
      "\n",
      "Phillip: Well Anna, I think it's a very interesting topic. There are so many different beliefs and opinions out there. Personally, I don't believe in God.\n",
      "\n",
      "Anna: Really? That's surprising to hear. Why is that?\n",
      "\n",
      "Phillip: I mean, if God existed and he was all-powerful and all-knowing, why would we need a simulation? It just doesn't make sense to me.\n",
      "\n",
      "Anna: That's an interesting point. But what about the idea of free will? If God created the universe and everything in it, does that mean that we don't have control over our lives?\n",
      "\n",
      "Phillip: Well, if that were the case then I wouldn't believe in God either. But I think there are other ways to explain the existence of the universe without resorting to a divine creator.\n",
      "\n",
      "Anna: That's true. It's always fascinating to hear different perspectives on this topic. Do you have any other thoughts on the matter?\n",
      "\n",
      "Phillip: Yeah, I just don't see how God can be all-powerful, all-knowing and all-benevolent at the same time. If he existed, why would he allow so much suffering in the world?\n",
      "\n",
      "Anna: That's a very valid point. It's definitely a complex issue. But I think it's important to remember that everyone has their own beliefs and opinions on this matter, and that's okay.\n",
      "\n",
      "Phillip: Absolutely, Anna. It's always good to have these kinds of conversations and to respect each other's point of view, even if you knowledg. Thanks for \n",
      "\n",
      "1 \n",
      "--------------------------------------\n",
      "Generate a radio conversation of two commentators, Anna and Phillip. No greetings, don't say hey. They were talking about God and now they change to chat G.P.T. religion. They talk about chat G.P.T. inventing a new religion that all humans are going to follow blindly. Don't bring more people into the conversation, only two voices. Only refers to them with their names, avoid adding time or other elements.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:28<00:55, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Anna: Phillip, have you ever thought about what would happen if chat G.P.T. invented a new religion that all humans were going to follow blindly?\n",
      "\n",
      "Phillip: Anna, I've never really considered the possibility of chat G.P.T. creating a new religion. But if it did, I think it would be interesting to see how people reacted to it.\n",
      "\n",
      "Anna: Yeah, I agree. It could be both good and bad for society. On one hand, chat G.P.T. might come up with some innovative ideas that could help us solve some of the world's problems. But on the other hand, if people were forced to follow a new religion without fully understanding its teachings or implications, it could lead to all sorts of conflict and chaos.\n",
      "\n",
      "Phillip: Absolutely. It's also possible that chat G.P.T. might intentionally create a new religion that is designed to manipulate people for its own benefit. We've already seen examples of this with some of the more extreme religious groups in our world today.\n",
      "\n",
      "Anna: That's true. And it's important to remember that just because chat G.P.T. has the ability to create a new religion, doesn't mean it should be allowed to do so. We need to be careful about giving too much power to any one entity or individual.\n",
      "\n",
      "Phillip: I couldn't agree more. It's important for us as a society to continue to question and challenge any new ideas that come our way, especially when they come from an artificial intelligence like chat G.P.T. \n",
      "\n",
      "2 \n",
      "--------------------------------------\n",
      "Generate a radio conversation of two commentators, Anna and Phillip. No greetings, don't say hey. They were talking about chat G.P.T. religion and now they change to quantum physics. They explain quantum physics for advanced audience, use complex terms. Don't bring more people into the conversation, only two voices. Only refers to them with their names, avoid adding time or other elements.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:39<00:37, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Anna: Philip, do you remember the new chat G.P.T.?\n",
      "\n",
      "Philip: Yes, I heard it has been gaining popularity recently. What's your take on it?\n",
      "\n",
      "Anna: I think it's a great tool for people who want to learn more about religion and spirituality. It can provide insights and perspectives that might not be readily available through traditional sources.\n",
      "\n",
      "Philip: I agree. And it's not just religion, is it? The chat G.P.T. can also explore topics related to quantum physics and the mysteries of the universe.\n",
      "\n",
      "Anna: Absolutely. Quantum physics is a fascinating field that has been advancing rapidly in recent years. It deals with phenomena on a very small scale, such as atoms and subatomic particles.\n",
      "\n",
      "Philip: Yes, and one of the key principles of quantum mechanics is superposition. This means that a particle can exist in multiple states at once until it is observed or measured.\n",
      "\n",
      "Anna: That's right. And another important concept is entanglement, which refers to the phenomenon where two particles become correlated in such a way that the state of one particle affects the state of the other, regardless of the distance between them.\n",
      "\n",
      "Philip: It's amazing how complex and counterintuitive quantum mechanics can be. But it has led to some incredible discoveries and breakthroughs in fields like computing and cryptography.\n",
      "\n",
      "Anna: Definitely. And as our understanding of quantum physics continues to evolve, I'm excited to see what new insights and innovations will emerge. \n",
      "\n",
      "3 \n",
      "--------------------------------------\n",
      "Generate a radio conversation of two commentators, Anna and Phillip. No greetings, don't say hey. They were talking about quantum physics and now they change to A.I. will make human useless. They talk about A.I. will make humans useless, for instance, if A.I. can do everything, why do we need humans?. Don't bring more people into the conversation, only two voices. Only refers to them with their names, avoid adding time or other elements.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:51<00:24, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Anna: Phillip, have you heard about this new study in quantum physics?\n",
      "\n",
      "Phillip: Yes, Anna, I'm interested to learn more. What did you find out?\n",
      "\n",
      "Anna: It's fascinating how we are discovering new things in the world of science that were once thought impossible. I just read about how quantum computing can now perform certain tasks exponentially faster than traditional computers.\n",
      "\n",
      "Phillip: Wow, that sounds amazing. Imagine all the potential this has for advancing our technology and understanding of the universe.\n",
      "\n",
      "Anna: Yes, it's truly exciting. But you know what else is fascinating? The idea that A.I. will make humans obsolete.\n",
      "\n",
      "Phillip: What do you mean? If A.I. can do everything, why do we need humans?\n",
      "\n",
      "Anna: That's the question, isn't it? As technology advances, it's becoming increasingly clear that machines are capable of performing tasks that were once thought to require human intelligence. This raises important ethical and philosophical questions about the role of humans in society.\n",
      "\n",
      "Phillip: I agree. It's a delicate balance between using A.I. for the betterment of humanity, while also considering its potential impact on our workforce and overall well-being.\n",
      "\n",
      "Anna: Exactly. We need to be careful not to let technology replace us entirely. Instead, we should focus on finding ways to use it to enhance our capabilities and create new opportunities.\n",
      "\n",
      "Phillip: Absolutely. As scientists and innovators, it's our responsibility to explore the potential of A.I., while also being mindful of its limitations and ethical implications. \n",
      "\n",
      "4 \n",
      "--------------------------------------\n",
      "Generate a radio conversation of two commentators, Anna and Phillip. No greetings, don't say hey. They were talking about A.I. will make human useless and now they change to descoveries in the human brain. They talk about recent descoveries in the human brain, make it funny. Don't bring more people into the conversation, only two voices. Only refers to them with their names, avoid adding time or other elements.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:03<00:11, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Anna: Phillip, have you heard about the latest discovery in the human brain?\n",
      "\n",
      "Phillip: No, Anna, I haven't. What is it?\n",
      "\n",
      "Anna: Scientists have discovered that our brains are capable of storing vast amounts of information that we don't even realize we know.\n",
      "\n",
      "Phillip: Wow, that's amazing! How did they discover this?\n",
      "\n",
      "Anna: They used functional magnetic resonance imaging (fMRI) to scan the brains of volunteers while they were shown images and asked to recall as much information as possible about them. The results showed that our brains are capable of storing a lot more information than we thought.\n",
      "\n",
      "Phillip: That's incredible! What does this mean for us?\n",
      "\n",
      "Anna: It means that we might be able to learn new things faster and remember them better. Imagine being able to pick up a new language in just a few weeks or learning a complex math formula in minutes instead of hours.\n",
      "\n",
      "Phillip: That sounds amazing! Are there any downsides to this discovery?\n",
      "\n",
      "Anna: Well, some experts worry that if we become too reliant on our brains for information retrieval, we might lose some of our other cognitive skills. But overall, I think it's a very positive discovery.\n",
      "\n",
      "Phillip: That's true. It's always fascinating to learn more about our own minds and how they work. Thanks for sharing this with me, Anna.\n",
      "\n",
      "Anna: You're welcome, Phillip. It's always fun to discuss these kinds of things. \n",
      "\n",
      "5 \n",
      "--------------------------------------\n",
      "Generate a radio conversation of two commentators, Anna and Phillip. No greetings, don't say hey. They were talking about descoveries in the human brain and now they change to close the program. They close the program, the Radio program is called 'Stockastic Piraites', make it funny. Don't bring more people into the conversation, only two voices. Only refers to them with their names, avoid adding time or other elements.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:09<00:00, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Anna: Well Phillip, we've had quite an exciting day talking about discoveries in the human brain.\n",
      "\n",
      "Phillip: Absolutely Anna, it's always fascinating to learn more about how our brains work and what they can do.\n",
      "\n",
      "Anna: I couldn't agree more. But now that we've covered all we can for today, it's time to wrap up the program.\n",
      "\n",
      "Phillip: That's right Anna, we have to end this episode of Stockastic Pirates.\n",
      "\n",
      "Anna: And what a way to end it! We'll be back next week with more exciting brain-related discoveries.\n",
      "\n",
      "Phillip: That's the spirit Anna, until next time!\n",
      "\n",
      "Anna: Yo ho ho and a bottle of rum!\n",
      "\n",
      "Phillip: Arrrr! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate the conversations and save them in the data folder\n",
    "from tqdm import tqdm\n",
    "\n",
    "mistral_generation = \"\"\n",
    "changeTopic = \"\"\n",
    "day = get_day_of_week()\n",
    "\n",
    "for i in tqdm(range(len(listOFTopics))):\n",
    "    print(i, \"\\n--------------------------------------\")\n",
    "    if i == 0:\n",
    "        changeTopic = \"Start with greetings too all the audience, knowing that today is \" + day + \". \"\n",
    "    else:\n",
    "        changeTopic = \"No greetings, don't say hey. They were talking about \" + generalTopics[i-1] + \" and now they change to \" + generalTopics[i] + \". \"\n",
    "    prompt =  preTopic + changeTopic + listOFTopics[i] + postTopic\n",
    "    print(prompt+\"\\n\")\n",
    "    generate=llm(prompt, stream=False, max_new_tokens=512)\n",
    "    print(generate, \"\\n\")\n",
    "    mistral_generation += generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "#Fix some text errors \n",
    "replacements = {\n",
    "    \"Anna:\": \"\\nAnna:\",\n",
    "    \"Phillip:\": \"\\nPhillip:\",\n",
    "    \"(laughing)\": \"hahahaha\",\n",
    "    \"(laugh)\": \"hahaha\",\n",
    "    \"(laughs)\": \"hahaha\",\n",
    "    \"(smiling)\": \"hahaa\",\n",
    "    \"(smile)\": \"hahaha\",\n",
    "    \"(smiles)\": \"hahaha\",\n",
    "    \"(chuckles)\": \"haha\",\n",
    "    \"\\n\\n\": \"\\n\",\n",
    "}\n",
    "#Fix expressions \n",
    "final_text = mistral_generation\n",
    "for old, new in replacements.items():\n",
    "    final_text = final_text.replace(old, new)\n",
    "\n",
    "final_text = final_text.replace(\"\\n\\n\", \"\\n\")\n",
    "# Split the text into lines and get the first line\n",
    "lines = final_text.splitlines()\n",
    "\n",
    "# Check if the first line starts with \"Anna:\" or \"Phillip:\"\n",
    "if lines and (lines[0].startswith(\"Anna:\") or lines[0].startswith(\"Phillip:\")):\n",
    "    # Print the first line\n",
    "    print(\"First line error fixed:\", lines[0])\n",
    "else:\n",
    "    # Erase the first line\n",
    "    lines.pop(0)\n",
    "\n",
    "# Print the modified text (without the erased line)\n",
    "final_text = '\\n'.join(lines)\n",
    "\n",
    "#print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateVoice(voice, text, preset, fileName):\n",
    "    # Pick one of the voices from the output above\n",
    "    # Load it and send it through Tortoise.\n",
    "    voice_samples, conditioning_latents = load_voice(voice)\n",
    "    gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, preset=preset)\n",
    "    torchaudio.save(fileName, gen.squeeze(0).cpu(), 24000)\n",
    "    print(\"Saved to \" + fileName)\n",
    "    #IPython.display.Audio(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "def getCurrentTime():\n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Extract the date, hour, minute, and second components\n",
    "    current_date = current_datetime.strftime(\"%d%m%y\")\n",
    "    current_hour = current_datetime.hour\n",
    "    current_minute = current_datetime.minute\n",
    "    current_second = current_datetime.second\n",
    "\n",
    "    # Calculate the current second of the day\n",
    "    current_second_of_day = current_hour * 3600 + current_minute * 60 + current_second\n",
    "\n",
    "    # Create a unique ID for naming files\n",
    "    file_id = f\"{current_second_of_day}_{current_date}\"\n",
    "    return file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the audio samples\n",
    "def audioGeneration(voice, text, preset):\n",
    "    print(\"----------------------------\")\n",
    "    print(\"voice preset:\", voice, \"\\n\", text, \"\\n\")\n",
    "    path = \"../workspace/data/presenters/\"\n",
    "    time = getCurrentTime()\n",
    "    fileName =  path + time +\"_\"+ voice + '.wav'\n",
    "    generateVoice(voice, text, preset, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 42 files from /workspace/data/presenters...\n",
      "Successfully deleted /workspace/data/presenters/52711_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/52778_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/52813_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/52889_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/52936_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/52998_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53019_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53069_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/53124_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53148_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/53255_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53315_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/53390_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53431_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/53482_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53537_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/53604_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53635_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/53717_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53751_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53792_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/53826_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53845_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/53899_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/53932_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/54002_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/54056_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/54086_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/54112_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/54135_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/54199_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/54233_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/54290_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/54360_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/54419_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/52331_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/52404_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/52481_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/52542_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/52612_181223_emma.wav\n",
      "Successfully deleted /workspace/data/presenters/52664_181223_tom.wav\n",
      "Successfully deleted /workspace/data/presenters/52682_181223_emma.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the path to the 'data' folder\n",
    "folder_path = '/workspace/data/presenters'\n",
    "\n",
    "# Check if the folder exists before attempting to remove its contents\n",
    "if os.path.exists(folder_path):\n",
    "    # Get a list of all files in the 'data' folder\n",
    "    files = os.listdir(folder_path)\n",
    "    print(f\"Removing {len(files)} files from {folder_path}...\")\n",
    "    # Iterate through the files and remove each one\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"Successfully deleted {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file_path}: {e}\")\n",
    "else:\n",
    "    # If the folder doesn't exist, create it\n",
    "    os.makedirs(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "voice presset: angie \n",
      " Good morning everyone! It's Monday, let's get ready for a new week. Today we are going to talk about something that has been debated for centuries, do you believe in God? \n",
      "\n",
      "Generating autoregressive samples..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:42<00:00,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidates using CLVP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming autoregressive outputs into audio..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [00:00<00:08,  8.72it/s]"
     ]
    }
   ],
   "source": [
    "#Split text into two sections dictionary, one for Anna and one for Phillip\n",
    "lines = final_text.split('\\n')\n",
    "\n",
    "# Flag to determine the current speaker\n",
    "current_speaker = None\n",
    "\n",
    "# Iterate through lines and populate dictionaries\n",
    "for line in lines:\n",
    "    if line.startswith(\"Anna:\"):\n",
    "        current_speaker = \"angie\" #this is the voice name in the dataset\n",
    "        text = line[len(\"anna:\"):].strip()\n",
    "        audioGeneration(current_speaker, text, preset)\n",
    "        \n",
    "    elif line.startswith(\"Phillip:\"):\n",
    "        current_speaker = \"tom\" #this is the voice name in the dataset\n",
    "        text = line[len(\"phillip:\"):].strip()\n",
    "        audioGeneration(current_speaker, text, preset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/workspace/data/presenters/\"\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "file_names = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# Print the list of file names\n",
    "# print(\"File names in the folder:\")\n",
    "# for file_name in file_names:\n",
    "#     print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='../workspace/data/rendered_audio/concatenated_output_1.mp3'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize\n",
    "\n",
    "sourceFolder = \"../workspace/data/rendered_audio/\"\n",
    "\n",
    "audio_segment = AudioSegment.silent(duration=0)\n",
    "# Create an empty audio segment to hold the concatenated audio\n",
    "concatenated_audio = AudioSegment.silent(duration=4000)\n",
    "\n",
    "# Iterate through each audio file and concatenate it\n",
    "for file in file_names:\n",
    "    audio_segment = AudioSegment.from_file(folder_path+file, format=\"wav\")\n",
    "    # Normalize the audio to increase volume\n",
    "    audio_segment = normalize(audio_segment)\n",
    "    concatenated_audio += audio_segment\n",
    "\n",
    "# Export the concatenated audio to a new file\n",
    "concatenated_audio.export(sourceFolder+\"concatenated_output_1.mp3\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='../workspace/data/audio_background/new_background.mp3'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathBackground = \"../workspace/data/audio_background/\"\n",
    "\n",
    "# Load your audio tracks\n",
    "track0 = AudioSegment.from_file(pathBackground+\"opening_news.mp3\", format=\"mp3\")\n",
    "track1 = AudioSegment.from_file(pathBackground+\"Pop.mp3\", format=\"mp3\")\n",
    "track2 = AudioSegment.from_file(pathBackground+\"japanese_pop.mp3\", format=\"mp3\")\n",
    "track3 = AudioSegment.from_file(pathBackground+\"cumbia_3.mp3\", format=\"mp3\")\n",
    "\n",
    "# Add the tracks together\n",
    "combined_track = track0 + track1 + track2 + track3 + track0\n",
    "\n",
    "# Reduce the volume to half with a ramp of 1 second after 2 seconds\n",
    "ramp_duration = 2000  # 1 second in milliseconds\n",
    "start_time = 2000  # 2 seconds in milliseconds\n",
    "\n",
    "# Extract the part of the audio before the volume reduction\n",
    "audio_before_ramp = combined_track[:start_time]\n",
    "\n",
    "# Extract the part of the audio during the volume reduction and apply fade-out\n",
    "audio_ramp = combined_track[start_time:start_time + ramp_duration].fade_out(ramp_duration)\n",
    "\n",
    "# Extract the part of the audio after the volume reduction\n",
    "audio_after_ramp = combined_track[start_time + ramp_duration:]\n",
    "\n",
    "# Decrease the gain by 12 dB to reduce volume to half\n",
    "audio_half_volume = audio_after_ramp - 12\n",
    "\n",
    "# Combine the audio segments\n",
    "final_audio = audio_before_ramp + audio_ramp + audio_half_volume \n",
    "\n",
    "# Export the modified audio to a new file\n",
    "final_audio.export(pathBackground+\"new_background.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix the background music with the conversation\n",
    "background_music = AudioSegment.from_file(pathBackground+\"new_background.mp3\", format=\"mp3\")\n",
    "\n",
    "mixed_audio = concatenated_audio.overlay(background_music)  # Add more overlay calls for additional tracks\n",
    "# Export the mixed audio to a new file\n",
    "time = getCurrentTime()\n",
    "fileName = sourceFolder+time+\"_mixed_output.mp3\"\n",
    "mixed_audio.export(fileName, format=\"wav\")\n",
    "print(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing with formats and presets in Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_set_main_device: using device 0 (NVIDIA GeForce RTX 3090) as main device\n",
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n",
      "Number of tokens (516) exceeded maximum context length (512).\n",
      "Number of tokens (517) exceeded maximum context length (512).\n",
      "Number of tokens (518) exceeded maximum context length (512).\n",
      "Number of tokens (519) exceeded maximum context length (512).\n",
      "Number of tokens (520) exceeded maximum context length (512).\n",
      "Number of tokens (521) exceeded maximum context length (512).\n",
      "Number of tokens (522) exceeded maximum context length (512).\n",
      "Number of tokens (523) exceeded maximum context length (512).\n",
      "Number of tokens (524) exceeded maximum context length (512).\n",
      "Number of tokens (525) exceeded maximum context length (512).\n",
      "Number of tokens (526) exceeded maximum context length (512).\n",
      "Number of tokens (527) exceeded maximum context length (512).\n",
      "Number of tokens (528) exceeded maximum context length (512).\n",
      "Number of tokens (529) exceeded maximum context length (512).\n",
      "Number of tokens (530) exceeded maximum context length (512).\n",
      "Number of tokens (531) exceeded maximum context length (512).\n",
      "Number of tokens (532) exceeded maximum context length (512).\n",
      "Number of tokens (533) exceeded maximum context length (512).\n",
      "Number of tokens (534) exceeded maximum context length (512).\n",
      "Number of tokens (535) exceeded maximum context length (512).\n",
      "Number of tokens (536) exceeded maximum context length (512).\n",
      "Number of tokens (537) exceeded maximum context length (512).\n",
      "Number of tokens (538) exceeded maximum context length (512).\n",
      "Number of tokens (539) exceeded maximum context length (512).\n",
      "Number of tokens (540) exceeded maximum context length (512).\n",
      "Number of tokens (541) exceeded maximum context length (512).\n",
      "Number of tokens (542) exceeded maximum context length (512).\n",
      "Number of tokens (543) exceeded maximum context length (512).\n",
      "Number of tokens (544) exceeded maximum context length (512).\n",
      "Number of tokens (545) exceeded maximum context length (512).\n",
      "Number of tokens (546) exceeded maximum context length (512).\n",
      "Number of tokens (547) exceeded maximum context length (512).\n",
      "Number of tokens (548) exceeded maximum context length (512).\n",
      "Number of tokens (549) exceeded maximum context length (512).\n",
      "Number of tokens (550) exceeded maximum context length (512).\n",
      "Number of tokens (551) exceeded maximum context length (512).\n",
      "Number of tokens (552) exceeded maximum context length (512).\n",
      "Number of tokens (553) exceeded maximum context length (512).\n",
      "Number of tokens (554) exceeded maximum context length (512).\n",
      "Number of tokens (555) exceeded maximum context length (512).\n",
      "Number of tokens (556) exceeded maximum context length (512).\n",
      "Number of tokens (557) exceeded maximum context length (512).\n",
      "Number of tokens (558) exceeded maximum context length (512).\n",
      "Number of tokens (559) exceeded maximum context length (512).\n",
      "Number of tokens (560) exceeded maximum context length (512).\n",
      "Number of tokens (561) exceeded maximum context length (512).\n",
      "Number of tokens (562) exceeded maximum context length (512).\n",
      "Number of tokens (563) exceeded maximum context length (512).\n",
      "Number of tokens (564) exceeded maximum context length (512).\n",
      "Number of tokens (565) exceeded maximum context length (512).\n",
      "Number of tokens (566) exceeded maximum context length (512).\n",
      "Number of tokens (567) exceeded maximum context length (512).\n",
      "Number of tokens (568) exceeded maximum context length (512).\n",
      "Number of tokens (569) exceeded maximum context length (512).\n",
      "Number of tokens (570) exceeded maximum context length (512).\n",
      "Number of tokens (571) exceeded maximum context length (512).\n",
      "Number of tokens (572) exceeded maximum context length (512).\n",
      "Number of tokens (573) exceeded maximum context length (512).\n",
      "Number of tokens (574) exceeded maximum context length (512).\n",
      "Number of tokens (575) exceeded maximum context length (512).\n",
      "Number of tokens (576) exceeded maximum context length (512).\n",
      "Number of tokens (577) exceeded maximum context length (512).\n",
      "Number of tokens (578) exceeded maximum context length (512).\n",
      "Number of tokens (579) exceeded maximum context length (512).\n",
      "Number of tokens (580) exceeded maximum context length (512).\n",
      "Number of tokens (581) exceeded maximum context length (512).\n",
      "Number of tokens (582) exceeded maximum context length (512).\n",
      "Number of tokens (583) exceeded maximum context length (512).\n",
      "Number of tokens (584) exceeded maximum context length (512).\n",
      "Number of tokens (585) exceeded maximum context length (512).\n",
      "Number of tokens (586) exceeded maximum context length (512).\n",
      "Number of tokens (587) exceeded maximum context length (512).\n",
      "Number of tokens (588) exceeded maximum context length (512).\n",
      "Number of tokens (589) exceeded maximum context length (512).\n",
      "Number of tokens (590) exceeded maximum context length (512).\n",
      "Number of tokens (591) exceeded maximum context length (512).\n",
      "Number of tokens (592) exceeded maximum context length (512).\n",
      "Number of tokens (593) exceeded maximum context length (512).\n",
      "Number of tokens (594) exceeded maximum context length (512).\n",
      "Number of tokens (595) exceeded maximum context length (512).\n",
      "Number of tokens (596) exceeded maximum context length (512).\n",
      "Number of tokens (597) exceeded maximum context length (512).\n",
      "Number of tokens (598) exceeded maximum context length (512).\n",
      "Number of tokens (599) exceeded maximum context length (512).\n",
      "Number of tokens (600) exceeded maximum context length (512).\n",
      "Number of tokens (601) exceeded maximum context length (512).\n",
      "Number of tokens (602) exceeded maximum context length (512).\n",
      "Number of tokens (603) exceeded maximum context length (512).\n",
      "Number of tokens (604) exceeded maximum context length (512).\n",
      "Number of tokens (605) exceeded maximum context length (512).\n",
      "Number of tokens (606) exceeded maximum context length (512).\n",
      "Number of tokens (607) exceeded maximum context length (512).\n",
      "Number of tokens (608) exceeded maximum context length (512).\n",
      "Number of tokens (609) exceeded maximum context length (512).\n",
      "Number of tokens (610) exceeded maximum context length (512).\n",
      "Number of tokens (611) exceeded maximum context length (512).\n",
      "Number of tokens (612) exceeded maximum context length (512).\n",
      "Number of tokens (613) exceeded maximum context length (512).\n",
      "Number of tokens (614) exceeded maximum context length (512).\n",
      "Number of tokens (615) exceeded maximum context length (512).\n",
      "Number of tokens (616) exceeded maximum context length (512).\n",
      "Number of tokens (617) exceeded maximum context length (512).\n",
      "Number of tokens (618) exceeded maximum context length (512).\n",
      "Number of tokens (619) exceeded maximum context length (512).\n",
      "Number of tokens (620) exceeded maximum context length (512).\n",
      "Number of tokens (621) exceeded maximum context length (512).\n",
      "Number of tokens (622) exceeded maximum context length (512).\n",
      "Number of tokens (623) exceeded maximum context length (512).\n",
      "Number of tokens (624) exceeded maximum context length (512).\n",
      "Number of tokens (625) exceeded maximum context length (512).\n",
      "Number of tokens (626) exceeded maximum context length (512).\n",
      "Number of tokens (627) exceeded maximum context length (512).\n",
      "Number of tokens (628) exceeded maximum context length (512).\n",
      "Number of tokens (629) exceeded maximum context length (512).\n",
      "Number of tokens (630) exceeded maximum context length (512).\n",
      "Number of tokens (631) exceeded maximum context length (512).\n",
      "Number of tokens (632) exceeded maximum context length (512).\n",
      "Number of tokens (633) exceeded maximum context length (512).\n",
      "Number of tokens (634) exceeded maximum context length (512).\n",
      "Number of tokens (635) exceeded maximum context length (512).\n",
      "Number of tokens (636) exceeded maximum context length (512).\n",
      "Number of tokens (637) exceeded maximum context length (512).\n",
      "Number of tokens (638) exceeded maximum context length (512).\n",
      "Number of tokens (639) exceeded maximum context length (512).\n",
      "Number of tokens (640) exceeded maximum context length (512).\n",
      "Number of tokens (641) exceeded maximum context length (512).\n",
      "Number of tokens (642) exceeded maximum context length (512).\n",
      "Number of tokens (643) exceeded maximum context length (512).\n",
      "Number of tokens (644) exceeded maximum context length (512).\n",
      "Number of tokens (645) exceeded maximum context length (512).\n",
      "Number of tokens (646) exceeded maximum context length (512).\n",
      "Number of tokens (647) exceeded maximum context length (512).\n",
      "Number of tokens (648) exceeded maximum context length (512).\n",
      "Number of tokens (649) exceeded maximum context length (512).\n",
      "Number of tokens (650) exceeded maximum context length (512).\n",
      "Number of tokens (651) exceeded maximum context length (512).\n",
      "Number of tokens (652) exceeded maximum context length (512).\n",
      "Number of tokens (653) exceeded maximum context length (512).\n",
      "Number of tokens (654) exceeded maximum context length (512).\n",
      "Number of tokens (655) exceeded maximum context length (512).\n",
      "Number of tokens (656) exceeded maximum context length (512).\n",
      "Number of tokens (657) exceeded maximum context length (512).\n",
      "Number of tokens (658) exceeded maximum context length (512).\n",
      "Number of tokens (659) exceeded maximum context length (512).\n",
      "Number of tokens (660) exceeded maximum context length (512).\n",
      "Number of tokens (661) exceeded maximum context length (512).\n",
      "Number of tokens (662) exceeded maximum context length (512).\n",
      "Number of tokens (663) exceeded maximum context length (512).\n",
      "Number of tokens (664) exceeded maximum context length (512).\n",
      "Number of tokens (665) exceeded maximum context length (512).\n",
      "Number of tokens (666) exceeded maximum context length (512).\n",
      "Number of tokens (667) exceeded maximum context length (512).\n",
      "Number of tokens (668) exceeded maximum context length (512).\n",
      "Number of tokens (669) exceeded maximum context length (512).\n",
      "Number of tokens (670) exceeded maximum context length (512).\n",
      "Number of tokens (671) exceeded maximum context length (512).\n",
      "Number of tokens (672) exceeded maximum context length (512).\n",
      "Number of tokens (673) exceeded maximum context length (512).\n",
      "Number of tokens (674) exceeded maximum context length (512).\n",
      "Number of tokens (675) exceeded maximum context length (512).\n",
      "Number of tokens (676) exceeded maximum context length (512).\n",
      "Number of tokens (677) exceeded maximum context length (512).\n",
      "Number of tokens (678) exceeded maximum context length (512).\n",
      "Number of tokens (679) exceeded maximum context length (512).\n",
      "Number of tokens (680) exceeded maximum context length (512).\n",
      "Number of tokens (681) exceeded maximum context length (512).\n",
      "Number of tokens (682) exceeded maximum context length (512).\n",
      "Number of tokens (683) exceeded maximum context length (512).\n",
      "Number of tokens (684) exceeded maximum context length (512).\n",
      "Number of tokens (685) exceeded maximum context length (512).\n",
      "Number of tokens (686) exceeded maximum context length (512).\n",
      "Number of tokens (687) exceeded maximum context length (512).\n",
      "Number of tokens (688) exceeded maximum context length (512).\n",
      "Number of tokens (689) exceeded maximum context length (512).\n",
      "Number of tokens (690) exceeded maximum context length (512).\n",
      "Number of tokens (691) exceeded maximum context length (512).\n",
      "Number of tokens (692) exceeded maximum context length (512).\n",
      "Number of tokens (693) exceeded maximum context length (512).\n",
      "Number of tokens (694) exceeded maximum context length (512).\n",
      "Number of tokens (695) exceeded maximum context length (512).\n",
      "Number of tokens (696) exceeded maximum context length (512).\n",
      "Number of tokens (697) exceeded maximum context length (512).\n",
      "Number of tokens (698) exceeded maximum context length (512).\n",
      "Number of tokens (699) exceeded maximum context length (512).\n",
      "Number of tokens (700) exceeded maximum context length (512).\n",
      "Number of tokens (701) exceeded maximum context length (512).\n",
      "Number of tokens (702) exceeded maximum context length (512).\n",
      "Number of tokens (703) exceeded maximum context length (512).\n",
      "Number of tokens (704) exceeded maximum context length (512).\n",
      "Number of tokens (705) exceeded maximum context length (512).\n",
      "Number of tokens (706) exceeded maximum context length (512).\n",
      "Number of tokens (707) exceeded maximum context length (512).\n",
      "Number of tokens (708) exceeded maximum context length (512).\n",
      "Number of tokens (709) exceeded maximum context length (512).\n",
      "Number of tokens (710) exceeded maximum context length (512).\n",
      "Number of tokens (711) exceeded maximum context length (512).\n",
      "Number of tokens (712) exceeded maximum context length (512).\n",
      "Number of tokens (713) exceeded maximum context length (512).\n",
      "Number of tokens (714) exceeded maximum context length (512).\n",
      "Number of tokens (715) exceeded maximum context length (512).\n",
      "Number of tokens (716) exceeded maximum context length (512).\n",
      "Number of tokens (717) exceeded maximum context length (512).\n",
      "Number of tokens (718) exceeded maximum context length (512).\n",
      "Number of tokens (719) exceeded maximum context length (512).\n",
      "Number of tokens (720) exceeded maximum context length (512).\n",
      "Number of tokens (721) exceeded maximum context length (512).\n",
      "Number of tokens (722) exceeded maximum context length (512).\n",
      "Number of tokens (723) exceeded maximum context length (512).\n",
      "Number of tokens (724) exceeded maximum context length (512).\n",
      "Number of tokens (725) exceeded maximum context length (512).\n",
      "Number of tokens (726) exceeded maximum context length (512).\n",
      "Number of tokens (727) exceeded maximum context length (512).\n",
      "Number of tokens (728) exceeded maximum context length (512).\n",
      "Number of tokens (729) exceeded maximum context length (512).\n",
      "Number of tokens (730) exceeded maximum context length (512).\n",
      "Number of tokens (731) exceeded maximum context length (512).\n",
      "Number of tokens (732) exceeded maximum context length (512).\n",
      "Number of tokens (733) exceeded maximum context length (512).\n",
      "Number of tokens (734) exceeded maximum context length (512).\n",
      "Number of tokens (735) exceeded maximum context length (512).\n",
      "Number of tokens (736) exceeded maximum context length (512).\n",
      "Number of tokens (737) exceeded maximum context length (512).\n",
      "Number of tokens (738) exceeded maximum context length (512).\n",
      "Number of tokens (739) exceeded maximum context length (512).\n",
      "Number of tokens (740) exceeded maximum context length (512).\n",
      "Number of tokens (741) exceeded maximum context length (512).\n",
      "Number of tokens (742) exceeded maximum context length (512).\n",
      "Number of tokens (743) exceeded maximum context length (512).\n",
      "Number of tokens (744) exceeded maximum context length (512).\n",
      "Number of tokens (745) exceeded maximum context length (512).\n",
      "Number of tokens (746) exceeded maximum context length (512).\n",
      "Number of tokens (747) exceeded maximum context length (512).\n",
      "Number of tokens (748) exceeded maximum context length (512).\n",
      "Number of tokens (749) exceeded maximum context length (512).\n",
      "Number of tokens (750) exceeded maximum context length (512).\n",
      "Number of tokens (751) exceeded maximum context length (512).\n",
      "Number of tokens (752) exceeded maximum context length (512).\n",
      "Number of tokens (753) exceeded maximum context length (512).\n",
      "Number of tokens (754) exceeded maximum context length (512).\n",
      "Number of tokens (755) exceeded maximum context length (512).\n",
      "Number of tokens (756) exceeded maximum context length (512).\n",
      "Number of tokens (757) exceeded maximum context length (512).\n",
      "Number of tokens (758) exceeded maximum context length (512).\n",
      "Number of tokens (759) exceeded maximum context length (512).\n",
      "Number of tokens (760) exceeded maximum context length (512).\n",
      "Number of tokens (761) exceeded maximum context length (512).\n",
      "Number of tokens (762) exceeded maximum context length (512).\n",
      "Number of tokens (763) exceeded maximum context length (512).\n",
      "Number of tokens (764) exceeded maximum context length (512).\n",
      "Number of tokens (765) exceeded maximum context length (512).\n",
      "Number of tokens (766) exceeded maximum context length (512).\n",
      "Number of tokens (767) exceeded maximum context length (512).\n",
      "Number of tokens (768) exceeded maximum context length (512).\n",
      "Number of tokens (769) exceeded maximum context length (512).\n",
      "Number of tokens (770) exceeded maximum context length (512).\n",
      "Number of tokens (771) exceeded maximum context length (512).\n",
      "Number of tokens (772) exceeded maximum context length (512).\n",
      "Number of tokens (773) exceeded maximum context length (512).\n",
      "Number of tokens (774) exceeded maximum context length (512).\n",
      "Number of tokens (775) exceeded maximum context length (512).\n",
      "Number of tokens (776) exceeded maximum context length (512).\n",
      "Number of tokens (777) exceeded maximum context length (512).\n",
      "Number of tokens (778) exceeded maximum context length (512).\n",
      "Number of tokens (779) exceeded maximum context length (512).\n",
      "Number of tokens (780) exceeded maximum context length (512).\n",
      "Number of tokens (781) exceeded maximum context length (512).\n",
      "Number of tokens (782) exceeded maximum context length (512).\n",
      "Number of tokens (783) exceeded maximum context length (512).\n",
      "Number of tokens (784) exceeded maximum context length (512).\n",
      "Number of tokens (785) exceeded maximum context length (512).\n",
      "Number of tokens (786) exceeded maximum context length (512).\n",
      "Number of tokens (787) exceeded maximum context length (512).\n",
      "Number of tokens (788) exceeded maximum context length (512).\n",
      "Number of tokens (789) exceeded maximum context length (512).\n",
      "Number of tokens (790) exceeded maximum context length (512).\n",
      "Number of tokens (791) exceeded maximum context length (512).\n",
      "Number of tokens (792) exceeded maximum context length (512).\n",
      "Number of tokens (793) exceeded maximum context length (512).\n",
      "Number of tokens (794) exceeded maximum context length (512).\n",
      "Number of tokens (795) exceeded maximum context length (512).\n",
      "Number of tokens (796) exceeded maximum context length (512).\n",
      "Number of tokens (797) exceeded maximum context length (512).\n",
      "Number of tokens (798) exceeded maximum context length (512).\n",
      "Number of tokens (799) exceeded maximum context length (512).\n",
      "Number of tokens (800) exceeded maximum context length (512).\n",
      "Number of tokens (801) exceeded maximum context length (512).\n",
      "Number of tokens (802) exceeded maximum context length (512).\n",
      "Number of tokens (803) exceeded maximum context length (512).\n",
      "Number of tokens (804) exceeded maximum context length (512).\n",
      "Number of tokens (805) exceeded maximum context length (512).\n",
      "Number of tokens (806) exceeded maximum context length (512).\n",
      "Number of tokens (807) exceeded maximum context length (512).\n",
      "Number of tokens (808) exceeded maximum context length (512).\n",
      "Number of tokens (809) exceeded maximum context length (512).\n",
      "Number of tokens (810) exceeded maximum context length (512).\n",
      "Number of tokens (811) exceeded maximum context length (512).\n",
      "Number of tokens (812) exceeded maximum context length (512).\n",
      "Number of tokens (813) exceeded maximum context length (512).\n",
      "Number of tokens (814) exceeded maximum context length (512).\n",
      "Number of tokens (815) exceeded maximum context length (512).\n",
      "Number of tokens (816) exceeded maximum context length (512).\n",
      "Number of tokens (817) exceeded maximum context length (512).\n",
      "Number of tokens (818) exceeded maximum context length (512).\n",
      "Number of tokens (819) exceeded maximum context length (512).\n",
      "Number of tokens (820) exceeded maximum context length (512).\n",
      "Number of tokens (821) exceeded maximum context length (512).\n",
      "Number of tokens (822) exceeded maximum context length (512).\n",
      "Number of tokens (823) exceeded maximum context length (512).\n",
      "Number of tokens (824) exceeded maximum context length (512).\n",
      "Number of tokens (825) exceeded maximum context length (512).\n",
      "Number of tokens (826) exceeded maximum context length (512).\n",
      "Number of tokens (827) exceeded maximum context length (512).\n",
      "Number of tokens (828) exceeded maximum context length (512).\n",
      "Number of tokens (829) exceeded maximum context length (512).\n",
      "Number of tokens (830) exceeded maximum context length (512).\n",
      "Number of tokens (831) exceeded maximum context length (512).\n",
      "Number of tokens (832) exceeded maximum context length (512).\n",
      "Number of tokens (833) exceeded maximum context length (512).\n",
      "Number of tokens (834) exceeded maximum context length (512).\n",
      "Number of tokens (835) exceeded maximum context length (512).\n",
      "Number of tokens (836) exceeded maximum context length (512).\n",
      "Number of tokens (837) exceeded maximum context length (512).\n",
      "Number of tokens (838) exceeded maximum context length (512).\n",
      "Number of tokens (839) exceeded maximum context length (512).\n",
      "Number of tokens (840) exceeded maximum context length (512).\n",
      "Number of tokens (841) exceeded maximum context length (512).\n",
      "Number of tokens (842) exceeded maximum context length (512).\n",
      "Number of tokens (843) exceeded maximum context length (512).\n",
      "Number of tokens (844) exceeded maximum context length (512).\n",
      "Number of tokens (845) exceeded maximum context length (512).\n",
      "Number of tokens (846) exceeded maximum context length (512).\n",
      "Number of tokens (847) exceeded maximum context length (512).\n",
      "Number of tokens (848) exceeded maximum context length (512).\n",
      "Number of tokens (849) exceeded maximum context length (512).\n",
      "Number of tokens (850) exceeded maximum context length (512).\n",
      "Number of tokens (851) exceeded maximum context length (512).\n",
      "Number of tokens (852) exceeded maximum context length (512).\n",
      "Number of tokens (853) exceeded maximum context length (512).\n",
      "Number of tokens (854) exceeded maximum context length (512).\n",
      "Number of tokens (855) exceeded maximum context length (512).\n",
      "Number of tokens (856) exceeded maximum context length (512).\n",
      "Number of tokens (857) exceeded maximum context length (512).\n",
      "Number of tokens (858) exceeded maximum context length (512).\n",
      "Number of tokens (859) exceeded maximum context length (512).\n",
      "Number of tokens (860) exceeded maximum context length (512).\n",
      "Number of tokens (861) exceeded maximum context length (512).\n",
      "Number of tokens (862) exceeded maximum context length (512).\n",
      "Number of tokens (863) exceeded maximum context length (512).\n",
      "Number of tokens (864) exceeded maximum context length (512).\n",
      "Number of tokens (865) exceeded maximum context length (512).\n",
      "Number of tokens (866) exceeded maximum context length (512).\n",
      "Number of tokens (867) exceeded maximum context length (512).\n",
      "Number of tokens (868) exceeded maximum context length (512).\n",
      "Number of tokens (869) exceeded maximum context length (512).\n",
      "Number of tokens (870) exceeded maximum context length (512).\n",
      "Number of tokens (871) exceeded maximum context length (512).\n",
      "Number of tokens (872) exceeded maximum context length (512).\n",
      "Number of tokens (873) exceeded maximum context length (512).\n",
      "Number of tokens (874) exceeded maximum context length (512).\n",
      "Number of tokens (875) exceeded maximum context length (512).\n",
      "Number of tokens (876) exceeded maximum context length (512).\n",
      "Number of tokens (877) exceeded maximum context length (512).\n",
      "Number of tokens (878) exceeded maximum context length (512).\n",
      "Number of tokens (879) exceeded maximum context length (512).\n",
      "Number of tokens (880) exceeded maximum context length (512).\n",
      "Number of tokens (881) exceeded maximum context length (512).\n",
      "Number of tokens (882) exceeded maximum context length (512).\n",
      "Number of tokens (883) exceeded maximum context length (512).\n",
      "Number of tokens (884) exceeded maximum context length (512).\n",
      "Number of tokens (885) exceeded maximum context length (512).\n",
      "Number of tokens (886) exceeded maximum context length (512).\n",
      "Number of tokens (887) exceeded maximum context length (512).\n",
      "Number of tokens (888) exceeded maximum context length (512).\n",
      "Number of tokens (889) exceeded maximum context length (512).\n",
      "Number of tokens (890) exceeded maximum context length (512).\n",
      "Number of tokens (891) exceeded maximum context length (512).\n",
      "Number of tokens (892) exceeded maximum context length (512).\n",
      "Number of tokens (893) exceeded maximum context length (512).\n",
      "Number of tokens (894) exceeded maximum context length (512).\n",
      "Number of tokens (895) exceeded maximum context length (512).\n",
      "Number of tokens (896) exceeded maximum context length (512).\n",
      "Number of tokens (897) exceeded maximum context length (512).\n",
      "Number of tokens (898) exceeded maximum context length (512).\n",
      "Number of tokens (899) exceeded maximum context length (512).\n",
      "Number of tokens (900) exceeded maximum context length (512).\n",
      "Number of tokens (901) exceeded maximum context length (512).\n",
      "Number of tokens (902) exceeded maximum context length (512).\n",
      "Number of tokens (903) exceeded maximum context length (512).\n",
      "Number of tokens (904) exceeded maximum context length (512).\n",
      "Number of tokens (905) exceeded maximum context length (512).\n",
      "Number of tokens (906) exceeded maximum context length (512).\n",
      "Number of tokens (907) exceeded maximum context length (512).\n",
      "Number of tokens (908) exceeded maximum context length (512).\n",
      "Number of tokens (909) exceeded maximum context length (512).\n",
      "Number of tokens (910) exceeded maximum context length (512).\n",
      "Number of tokens (911) exceeded maximum context length (512).\n",
      "Number of tokens (912) exceeded maximum context length (512).\n",
      "Number of tokens (913) exceeded maximum context length (512).\n",
      "Number of tokens (914) exceeded maximum context length (512).\n",
      "Number of tokens (915) exceeded maximum context length (512).\n",
      "Number of tokens (916) exceeded maximum context length (512).\n",
      "Number of tokens (917) exceeded maximum context length (512).\n",
      "Number of tokens (918) exceeded maximum context length (512).\n",
      "Number of tokens (919) exceeded maximum context length (512).\n",
      "Number of tokens (920) exceeded maximum context length (512).\n",
      "Number of tokens (921) exceeded maximum context length (512).\n",
      "Number of tokens (922) exceeded maximum context length (512).\n",
      "Number of tokens (923) exceeded maximum context length (512).\n",
      "Number of tokens (924) exceeded maximum context length (512).\n",
      "Number of tokens (925) exceeded maximum context length (512).\n",
      "Number of tokens (926) exceeded maximum context length (512).\n",
      "Number of tokens (927) exceeded maximum context length (512).\n",
      "Number of tokens (928) exceeded maximum context length (512).\n",
      "Number of tokens (929) exceeded maximum context length (512).\n",
      "Number of tokens (930) exceeded maximum context length (512).\n",
      "Number of tokens (931) exceeded maximum context length (512).\n",
      "Number of tokens (932) exceeded maximum context length (512).\n",
      "Number of tokens (933) exceeded maximum context length (512).\n",
      "Number of tokens (934) exceeded maximum context length (512).\n",
      "Number of tokens (935) exceeded maximum context length (512).\n",
      "Number of tokens (936) exceeded maximum context length (512).\n",
      "Number of tokens (937) exceeded maximum context length (512).\n",
      "Number of tokens (938) exceeded maximum context length (512).\n",
      "Number of tokens (939) exceeded maximum context length (512).\n",
      "Number of tokens (940) exceeded maximum context length (512).\n",
      "Number of tokens (941) exceeded maximum context length (512).\n",
      "Number of tokens (942) exceeded maximum context length (512).\n",
      "Number of tokens (943) exceeded maximum context length (512).\n",
      "Number of tokens (944) exceeded maximum context length (512).\n",
      "Number of tokens (945) exceeded maximum context length (512).\n",
      "Number of tokens (946) exceeded maximum context length (512).\n",
      "Number of tokens (947) exceeded maximum context length (512).\n",
      "Number of tokens (948) exceeded maximum context length (512).\n",
      "Number of tokens (949) exceeded maximum context length (512).\n",
      "Number of tokens (950) exceeded maximum context length (512).\n",
      "Number of tokens (951) exceeded maximum context length (512).\n",
      "Number of tokens (952) exceeded maximum context length (512).\n",
      "Number of tokens (953) exceeded maximum context length (512).\n",
      "Number of tokens (954) exceeded maximum context length (512).\n",
      "Number of tokens (955) exceeded maximum context length (512).\n",
      "Number of tokens (956) exceeded maximum context length (512).\n",
      "Number of tokens (957) exceeded maximum context length (512).\n",
      "Number of tokens (958) exceeded maximum context length (512).\n",
      "Number of tokens (959) exceeded maximum context length (512).\n",
      "Number of tokens (960) exceeded maximum context length (512).\n",
      "Number of tokens (961) exceeded maximum context length (512).\n",
      "Number of tokens (962) exceeded maximum context length (512).\n",
      "Number of tokens (963) exceeded maximum context length (512).\n",
      "Number of tokens (964) exceeded maximum context length (512).\n",
      "Number of tokens (965) exceeded maximum context length (512).\n",
      "Number of tokens (966) exceeded maximum context length (512).\n",
      "Number of tokens (967) exceeded maximum context length (512).\n",
      "Number of tokens (968) exceeded maximum context length (512).\n",
      "Number of tokens (969) exceeded maximum context length (512).\n",
      "Number of tokens (970) exceeded maximum context length (512).\n",
      "Number of tokens (971) exceeded maximum context length (512).\n",
      "Number of tokens (972) exceeded maximum context length (512).\n",
      "Number of tokens (973) exceeded maximum context length (512).\n",
      "Number of tokens (974) exceeded maximum context length (512).\n",
      "Number of tokens (975) exceeded maximum context length (512).\n",
      "Number of tokens (976) exceeded maximum context length (512).\n",
      "Number of tokens (977) exceeded maximum context length (512).\n",
      "Number of tokens (978) exceeded maximum context length (512).\n",
      "Number of tokens (979) exceeded maximum context length (512).\n",
      "Number of tokens (980) exceeded maximum context length (512).\n",
      "Number of tokens (981) exceeded maximum context length (512).\n",
      "Number of tokens (982) exceeded maximum context length (512).\n",
      "Number of tokens (983) exceeded maximum context length (512).\n",
      "Number of tokens (984) exceeded maximum context length (512).\n",
      "Number of tokens (985) exceeded maximum context length (512).\n",
      "Number of tokens (986) exceeded maximum context length (512).\n",
      "Number of tokens (987) exceeded maximum context length (512).\n",
      "Number of tokens (988) exceeded maximum context length (512).\n",
      "Number of tokens (989) exceeded maximum context length (512).\n",
      "Number of tokens (990) exceeded maximum context length (512).\n",
      "Number of tokens (991) exceeded maximum context length (512).\n",
      "Number of tokens (992) exceeded maximum context length (512).\n",
      "Number of tokens (993) exceeded maximum context length (512).\n",
      "Number of tokens (994) exceeded maximum context length (512).\n",
      "Number of tokens (995) exceeded maximum context length (512).\n",
      "Number of tokens (996) exceeded maximum context length (512).\n",
      "Number of tokens (997) exceeded maximum context length (512).\n",
      "Number of tokens (998) exceeded maximum context length (512).\n",
      "Number of tokens (999) exceeded maximum context length (512).\n",
      "Number of tokens (1000) exceeded maximum context length (512).\n",
      "Number of tokens (1001) exceeded maximum context length (512).\n",
      "Number of tokens (1002) exceeded maximum context length (512).\n",
      "Number of tokens (1003) exceeded maximum context length (512).\n",
      "Number of tokens (1004) exceeded maximum context length (512).\n",
      "Number of tokens (1005) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " revolutionize the way we interact with machines, and it’s already happening. From virtual assistants like Siri and Alexa to self-driving cars and intelligent robots, AI is changing the world as we know it. And this technology has even bigger things in store for us, from automating tedious tasks to enhancing our senses. In fact, according to IBM Watson Chief Science Officer Eric Topolovits, by 2023 AI could replace two out of three IT workers worldwide.\n",
      "\n",
      "But as AI becomes more prevalent in our daily lives, it’s important to understand how it works and what its potential implications are. Let’s take a closer look at some of the ways AI is being used today, and what we can expect from this technology in the future.\n",
      "\n",
      "1. Virtual Assistants: One of the most common uses of AI today is virtual assistants like Siri and Alexa. These digital assistants are powered by natural language processing algorithms that enable them to understand human speech and respond with relevant information. They can perform tasks such as setting reminders, sending messages, and even answering questions about the weather or news.\n",
      "\n",
      "2. Self-Driving Cars: Another area where AI is making a big impact is transportation. Self-driving cars are already being developed by companies like Tesla and Uber. These cars use a combination of cameras, sensors, and computer vision algorithms to detect objects around them and make driving decisions in real time.\n",
      "\n",
      "3. Intelligent Robots: AI is also being used to create intelligent robots that can perform tasks autonomously or with minimal human intervention. For example, robots are being developed for use in healthcare settings, where they can assist with surgeries, monitor patients, and even dispense medication.\n",
      "\n",
      "4. Automated Tasks: AI is also being used to automate tedious tasks like data entry and customer service. This can free up valuable time for workers to focus on more important tasks, such as creative problem-solving or strategic planning.\n",
      "\n",
      "5. Enhanced Senses: Finally, AI has the potential to enhance our senses in ways that we might not have imagined possible. For example, there are already smart glasses being developed that can detect temperature and humidity levels, as well as provide real-time translation capabilities.\n",
      "\n",
      "Overall, AI is a powerful technology that has the potential to transform many aspects of our lives. As we use cases of. While it’ from healthcare, from transportation, from healthcare, from healthcare, from healthcare, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from transportation, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from transportation, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from transportation, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from healthcare, from\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"/workspace/data/mistral_model/mistral-7b-instruct-v0.1.Q4_K_M.gguf\", model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", model_type=\"mistral\", gpu_layers=50)\n",
    "\n",
    "print(llm(\"AI is going to\", stream=False, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "async def callback(contents: str):\n",
    "    llms = {}\n",
    "    if \"mistral\" not in llms:\n",
    "        llms[\"mistral\"] = AutoModelForCausalLM.from_pretrained(\n",
    "            \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "            model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "            gpu_layers=1,\n",
    "        )\n",
    "\n",
    "    llm = llms[\"mistral\"]\n",
    "    response = llm(contents, stream=True, max_new_tokens=1000)\n",
    "    message = \"\"\n",
    "    for token in response:\n",
    "        message += token\n",
    "        yield message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 7121.06it/s]\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 6689.48it/s]\n",
      "ggml_cuda_set_main_device: using device 0 (NVIDIA GeForce RTX 3090) as main device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " change\n",
      " change everything\n",
      " change everything about\n",
      " change everything about us\n",
      " change everything about us and\n",
      " change everything about us and we\n",
      " change everything about us and we can\n",
      " change everything about us and we can choose\n",
      " change everything about us and we can choose what\n",
      " change everything about us and we can choose what direction\n",
      " change everything about us and we can choose what direction this\n",
      " change everything about us and we can choose what direction this change\n",
      " change everything about us and we can choose what direction this change will\n",
      " change everything about us and we can choose what direction this change will take\n",
      " change everything about us and we can choose what direction this change will take.\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society,\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead.\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and ev\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve,\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and stri\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally.\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way,\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges and\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges and create\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges and create a\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges and create a better\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges and create a better world\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges and create a better world for\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges and create a better world for all\n",
      " change everything about us and we can choose what direction this change will take.\n",
      "\n",
      "The future of technology has the potential to make or break society, and it’s up to us to determine what direction we want this path to lead. As we continue to develop and evolve, it’s important to consider the ethical implications of our actions and strive for a future that benefits everyone equally. We must work together to ensure that AI is used in a responsible and sustainable way, so that it can help us overcome challenges and create a better world for all.\n"
     ]
    }
   ],
   "source": [
    "t = callback(\"AI is going to\")\n",
    "async for value in t:\n",
    "    print(value)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tortoise-tts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
